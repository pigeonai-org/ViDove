[project]
name = "vidove"
version = "0.1.1"
requires-python = ">=3.10, <3.11"
dependencies = [
    # Core YAML/Config
    "PyYAML>=6.0.2",
    # Media Processing
    "pydub>=0.25.1",
    "yt-dlp>=2023.0.0",
    "ffmpeg-python>=0.2.0",
    # Audio/Speech Recognition (Core - API-based)
    "librosa>=0.11.0",
    # ML/AI Core
    "torch>=2.2.0",
    "torchaudio>=2.2.0",
    "transformers>=4.35.2",
    "numpy>=1.23.0",
    "pandas>=1.5.0",
    "numba>=0.56.0",
    "llvmlite>=0.40.0",
    # HTTP/API Clients
    "aiohttp>=3.8.4, <4.0.0",
    "httpx>=0.27.0, <0.28.0",
    "requests>=2.28.0",
    "openai>=1.35.0,<2.0.0",
    # Knowledge/RAG (Core)
    "llama-index>=0.8.42",
    "llama-index-embeddings-cohere>=0.5.0",
    "llama-index-llms-azure-openai>=0.1.10",
    "tavily-python>=0.1.9",
    # Utilities
    "cryptography>=45.0.3",
    "pydantic>=2.0.0",
    "tqdm>=4.65.0",
    "typing-extensions>=4.8.0",
    "google-genai>=1.1.0",
    "opencv-python>=4.8.1.78",
    "streamlit>=1.51.0",
]

[project.optional-dependencies]
# UI/Web Frameworks (for local Streamlit/Gradio/Flask apps)
ui = [
    "streamlit>=1.30.0",
    "gradio>=3.36.1",
    "flask>=2.3.0",
    "starlette>=0.36.0",
    "fastapi>=0.110.0",
    "uvicorn>=0.27.0",
]

# Evaluation/Testing Tools
evaluation = [
    "sacrebleu>=2.3.0",
    "pyenchant>=3.2.0",
    "langchain>=0.2.3",
    "langchain-core>=0.2.43",
    "langchain-community>=0.2.4",
]

# Local Audio Models (optional - can use OpenAI Whisper API instead)
audio-local = [
    "openai-whisper>=20230314",
    "stable-ts>=2.9.0",
]

# Advanced Audio Features (optional - can use Pyannote API instead)
audio-advanced = [
    "pyannote-audio>=3.3.0",
]

# Vision Features (CLIP, OpenCV)
vision = [
    "clip @ git+https://github.com/openai/CLIP.git",
]

# All optional features combined
all = [
    "vidove[ui,evaluation,audio-local,audio-advanced,vision]",
]

[tool.uv]
# Allow uv to resolve conflicts
resolution = "highest"

[tool.uv.sources]
torch = [
  { index = "pytorch-cpu" },
]
torchvision = [
  { index = "pytorch-cpu" },
]

# Default to CPU-only PyTorch to prevent automatic CUDA downloads
# This significantly reduces Docker image size and build time
# For GPU support: UV_EXTRA_INDEX_URL=https://download.pytorch.org/whl/cu121 uv sync
[[tool.uv.index]]
name = "pytorch-cpu"
url = "https://download.pytorch.org/whl/cpu"
explicit = true


